seed_everything: 2024
trainer:
  max_epochs: 20
  max_time: 00:02:00:00
  callbacks:
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val_loss
        patience: 5
        verbose: true
  logger:
    - class_path: lightning.pytorch.loggers.CSVLogger
      init_args:
        save_dir: ./korean_models
  accelerator: auto
  devices: 1
model:
  dropout: 0.3
  encoder: klue/bert-base
  pooling_layers: 4
  reverse_edits: true
  use_upos: true
  use_xpos: true
  use_lemma: true
  use_feats: true
  encoder_optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 2e-5
      weight_decay: 0.01
  encoder_scheduler:
    class_path: udtube.schedulers.WarmupInverseSquareRoot
    init_args:
      warmup_epochs: 2
  classifier_optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 1e-3
      weight_decay: 0.01
  classifier_scheduler:
    class_path: lightning.pytorch.cli.ReduceLROnPlateau
    init_args:
      monitor: val_loss
      factor: 0.5
      patience: 3
data:
  model_dir: ./korean_models
  train: ./korean_training_data/UD_Korean-GSD-master/ko_gsd-ud-train.conllu
  val: ./korean_training_data/UD_Korean-GSD-master/ko_gsd-ud-dev.conllu
  test: ./korean_training_data/UD_Korean-GSD-master/ko_gsd-ud-test.conllu
  predict: ./korean_training_data/UD_Korean-GSD-master/ko_gsd-ud-test.conllu
  batch_size: 16
  num_workers: 2
checkpoint:
  filename: "korean-model-{epoch:03d}-{val_loss:.4f}"
  monitor: val_loss
  verbose: true
  save_top_k: 3
  mode: min
prediction:
  path: ./korean_models/predictions.conllu