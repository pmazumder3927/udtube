seed_everything: 2024
trainer:
  max_epochs: 3
  max_time: 00:00:30:00
  callbacks:
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val_loss
        patience: 2
        verbose: true
  logger:
    - class_path: lightning.pytorch.loggers.CSVLogger
      init_args:
        save_dir: ./korean_models
  accelerator: auto
  devices: 1
  limit_train_batches: 100
  limit_val_batches: 20
model:
  dropout: 0.3
  encoder: google-bert/bert-base-multilingual-cased
  pooling_layers: 4
  reverse_edits: true
  use_upos: true
  use_xpos: true
  use_lemma: true
  use_feats: true
  encoder_optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 2e-5
      weight_decay: 0.01
  encoder_scheduler:
    class_path: udtube.schedulers.Dummy
  classifier_optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 1e-3
      weight_decay: 0.01
  classifier_scheduler:
    class_path: udtube.schedulers.Dummy
data:
  model_dir: ./korean_models
  train: ./korean_training_data/UD_Korean-GSD-master/ko_gsd-ud-train.conllu
  val: ./korean_training_data/UD_Korean-GSD-master/ko_gsd-ud-dev.conllu
  test: ./korean_training_data/UD_Korean-GSD-master/ko_gsd-ud-test.conllu
  predict: ./korean_data/sample.conllu
  batch_size: 8
checkpoint:
  filename: "korean-quick-{epoch:03d}-{val_loss:.4f}"
  monitor: val_loss
  verbose: true
  save_top_k: 1
  mode: min
prediction:
  path: ./korean_models/predictions.conllu